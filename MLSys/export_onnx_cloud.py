import os
import shutil
from optimum.exporters.onnx import main_export
from transformers import AutoTokenizer
from modelscope.hub.snapshot_download import snapshot_download

# --- 1. ä½¿ç”¨ ModelScope è·å–æ¨¡å‹çš„å®‰å…¨æœ¬åœ°è·¯å¾„ ---
model_id = "Qwen/Qwen1.5-1.8B-Chat"
print(f"====================================================================")
print(f"æ­¥éª¤ 1/3: æ­£åœ¨ç¡®è®¤æ¨¡å‹ '{model_id}' çš„æœ¬åœ°è·¯å¾„...")
print(f"====================================================================")

try:
    local_model_path = snapshot_download(model_id, cache_dir='./model_cache')
    print(f"âœ… æ¨¡å‹å·²å°±ç»ªï¼Œæœ¬åœ°è·¯å¾„ä¸º: {local_model_path}")
except Exception as e:
    print(f"âŒ è·å–æ¨¡å‹è·¯å¾„å¤±è´¥ï¼é”™è¯¯: {e}")
    exit()

# --- 2. å®šä¹‰ä½ æŒ‡å®šçš„ ONNX è¾“å‡ºè·¯å¾„ ---
onnx_output_path = "./llama-onnx"  # <--- ä¿®æ”¹åœ¨è¿™é‡Œï¼

# åœ¨å¯¼å‡ºå‰ï¼Œå…ˆæ¸…ç†ä¸€ä¸‹ç›®æ ‡æ–‡ä»¶å¤¹ï¼Œé˜²æ­¢æ—§æ–‡ä»¶å¹²æ‰°
if os.path.exists(onnx_output_path):
    print(f"\nè­¦å‘Šï¼šå‘ç°å·²å­˜åœ¨çš„è¾“å‡ºç›®å½• '{onnx_output_path}'ï¼Œå°†è¿›è¡Œæ¸…ç†ã€‚")
    shutil.rmtree(onnx_output_path)
print(f"\nONNX æ¨¡å‹å°†ä¿å­˜åˆ°ä½ æŒ‡å®šçš„ç›®å½•: {onnx_output_path}")


# --- 3. ä»æœ¬åœ°è·¯å¾„å¯¼å‡ºæ¨¡å‹ ---
print(f"\n====================================================================")
print(f"æ­¥éª¤ 2/3: å¼€å§‹ä»æœ¬åœ°è·¯å¾„å°†æ¨¡å‹å¯¼å‡ºä¸º ONNX...")
print(f"====================================================================")
try:
    main_export(
        model_name_or_path=local_model_path,
        output=onnx_output_path,
        task="text-generation-with-past",
        do_constant_folding=True,
        trust_remote_code=True,
    )
    print(f"\nâœ… æ¨¡å‹æˆåŠŸå¯¼å‡ºä¸º ONNX æ ¼å¼åˆ°: {onnx_output_path}")

except Exception as e:
    print(f"\nâŒ æ¨¡å‹å¯¼å‡ºå¤±è´¥ï¼é”™è¯¯: {e}")
    exit()

# --- 4. ä¿å­˜åˆ†è¯å™¨ ---
print(f"\n====================================================================")
print(f"æ­¥éª¤ 3/3: æ­£åœ¨ä¿å­˜åˆ†è¯å™¨...")
print(f"====================================================================")
try:
    tokenizer = AutoTokenizer.from_pretrained(local_model_path, trust_remote_code=True)
    tokenizer.save_pretrained(onnx_output_path)
    print(f"âœ… åˆ†è¯å™¨æˆåŠŸä¿å­˜åˆ°: {onnx_output_path}")
    print(f"\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼æ‰€æœ‰æ­¥éª¤å·²æˆåŠŸå®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰")

except Exception as e:
    print(f"\nâŒ åˆ†è¯å™¨ä¿å­˜å¤±è´¥ï¼é”™è¯¯: {e}")